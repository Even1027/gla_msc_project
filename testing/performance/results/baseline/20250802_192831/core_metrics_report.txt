=================================================
CORE METRICS REPORT - ACADEMIC RESEARCH
Microservices Consistency Mechanisms Evaluation
=================================================
Experimental Configuration:
  Test Timestamp: Sat Aug  2 19:30:33 GMT 2025
  Test Duration: 120 seconds
  Target Request Rate: 300 requests/minute
  Total Requests Sent: 172
  Successful Requests: 172
  Failed Requests: 0

=================================================
FOUR CORE METRICS (Literature-Supported)
=================================================

1. SYSTEM THROUGHPUT
   ✓ Successful Requests/Second: 1.43
   📚 Literature Support: Villamizar et al. (2015), Dragoni et al. (2017)
   📝 Definition: Number of successful order requests processed per second
   🎯 Academic Significance: Primary performance indicator for microservices evaluation

2. RESPONSE TIME DISTRIBUTION  
   ✓ P50 (Median): 16 ms
   ✓ P95 (95th Percentile): 20 ms
   ✓ P99 (99th Percentile): 24 ms
   ✓ Average Response Time: 15.39 ms
   📚 Literature Support: Dean & Barroso (2013) "The tail at scale"
   📝 Definition: API request response time percentile distribution
   🎯 Academic Significance: Tail latency critical for large-scale system performance

3. ERROR RATE
   ✓ Failed Requests: 0
   ✓ Total Requests: 172
   ✓ Error Rate: 0.00%
   📚 Literature Support: Newman (2015), Fowler & Lewis (2014)
   📝 Definition: Percentage of failed requests relative to total requests
   🎯 Academic Significance: System reliability and robustness indicator

4. CACHE EFFECTIVENESS (Idempotency Mechanism)
   ✓ Repeated Requests: 53
   ✓ Successfully Handled Repeats: 53
   ✓ Cache Effectiveness: 100.00%
   📚 Literature Support: Nishtala et al. (2013) Facebook Memcache Study
   📝 Definition: Success rate of Redis idempotency cache in handling duplicate requests
   🎯 Academic Significance: Consistency mechanism efficiency measurement

=================================================
EXPERIMENTAL DATA FILES
=================================================
Detailed Results CSV: ../results/baseline/20250802_192831/detailed_results.csv
Response Time Data: ../results/baseline/20250802_192831/response_times.txt
Core Metrics Report: ../results/baseline/20250802_192831/core_metrics_report.txt
Initial System State: ../results/baseline/20250802_192831/initial_inventory.json
Final System State: ../results/baseline/20250802_192831/final_inventory.json

=================================================
ACADEMIC CITATION TEMPLATE
=================================================
"This study employs four literature-supported core metrics to evaluate 
microservices consistency mechanism performance. Throughput and response 
time distribution follow the methodological framework established by 
Dean & Barroso (2013) and Villamizar et al. (2015) for microservices 
performance assessment. Error rate measurement aligns with Newman (2015)'s 
reliability evaluation framework. Cache effectiveness evaluation adapts 
the large-scale caching system assessment approach from Nishtala et al. (2013)."

=================================================
EXPERIMENTAL VALIDATION STATUS
=================================================
✅ Data Collection: Complete
✅ Metrics Calculation: Complete  
✅ Literature Alignment: Verified
✅ Academic Standards: Compliant
🎓 Ready for thesis integration

=================================================
PERFORMANCE ANALYSIS SUMMARY
=================================================
System Performance: MEDIUM
Response Time Performance: EXCELLENT
System Reliability: HIGH
Idempotency Effectiveness: EXCELLENT
