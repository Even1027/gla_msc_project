=================================================
CORE METRICS REPORT - ACADEMIC RESEARCH
Microservices Consistency Mechanisms Evaluation
=================================================
Experimental Configuration:
  Test Timestamp: Sat Aug  2 19:41:31 GMT 2025
  Test Duration: 120 seconds
  Target Request Rate: 300 requests/minute
  Total Requests Sent: 169
  Successful Requests: 169
  Failed Requests: 0

=================================================
FOUR CORE METRICS (Literature-Supported)
=================================================

1. SYSTEM THROUGHPUT
   âœ“ Successful Requests/Second: 1.41
   ğŸ“š Literature Support: Villamizar et al. (2015), Dragoni et al. (2017)
   ğŸ“ Definition: Number of successful order requests processed per second
   ğŸ¯ Academic Significance: Primary performance indicator for microservices evaluation

2. RESPONSE TIME DISTRIBUTION  
   âœ“ P50 (Median): 14 ms
   âœ“ P95 (95th Percentile): 27 ms
   âœ“ P99 (99th Percentile): 29 ms
   âœ“ Average Response Time: 14.82 ms
   ğŸ“š Literature Support: Dean & Barroso (2013) "The tail at scale"
   ğŸ“ Definition: API request response time percentile distribution
   ğŸ¯ Academic Significance: Tail latency critical for large-scale system performance

3. ERROR RATE
   âœ“ Failed Requests: 0
   âœ“ Total Requests: 169
   âœ“ Error Rate: 0.00%
   ğŸ“š Literature Support: Newman (2015), Fowler & Lewis (2014)
   ğŸ“ Definition: Percentage of failed requests relative to total requests
   ğŸ¯ Academic Significance: System reliability and robustness indicator

4. CACHE EFFECTIVENESS (Idempotency Mechanism)
   âœ“ Repeated Requests: 50
   âœ“ Successfully Handled Repeats: 50
   âœ“ Cache Effectiveness: 100.00%
   ğŸ“š Literature Support: Nishtala et al. (2013) Facebook Memcache Study
   ğŸ“ Definition: Success rate of Redis idempotency cache in handling duplicate requests
   ğŸ¯ Academic Significance: Consistency mechanism efficiency measurement

=================================================
EXPERIMENTAL DATA FILES
=================================================
Detailed Results CSV: ../results/baseline/20250802_193929/detailed_results.csv
Response Time Data: ../results/baseline/20250802_193929/response_times.txt
Core Metrics Report: ../results/baseline/20250802_193929/core_metrics_report.txt
Initial System State: ../results/baseline/20250802_193929/initial_inventory.json
Final System State: ../results/baseline/20250802_193929/final_inventory.json

=================================================
ACADEMIC CITATION TEMPLATE
=================================================
"This study employs four literature-supported core metrics to evaluate 
microservices consistency mechanism performance. Throughput and response 
time distribution follow the methodological framework established by 
Dean & Barroso (2013) and Villamizar et al. (2015) for microservices 
performance assessment. Error rate measurement aligns with Newman (2015)'s 
reliability evaluation framework. Cache effectiveness evaluation adapts 
the large-scale caching system assessment approach from Nishtala et al. (2013)."

=================================================
EXPERIMENTAL VALIDATION STATUS
=================================================
âœ… Data Collection: Complete
âœ… Metrics Calculation: Complete  
âœ… Literature Alignment: Verified
âœ… Academic Standards: Compliant
ğŸ“ Ready for thesis integration

=================================================
PERFORMANCE ANALYSIS SUMMARY
=================================================
System Performance: MEDIUM
Response Time Performance: EXCELLENT
System Reliability: HIGH
Idempotency Effectiveness: EXCELLENT
