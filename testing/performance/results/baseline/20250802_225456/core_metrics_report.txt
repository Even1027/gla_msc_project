=================================================
CORE METRICS REPORT - ACADEMIC RESEARCH
Microservices Consistency Mechanisms Evaluation
=================================================
Experimental Configuration:
  Test Timestamp: Sat Aug  2 22:55:56 GMT 2025
  Test Duration: 60 seconds
  Target Request Rate: 1800 requests/minute
  Total Requests Sent: 90
  Successful Requests: 90
  Failed Requests: 0

=================================================
FOUR CORE METRICS (Literature-Supported)
=================================================

1. SYSTEM THROUGHPUT
   ✓ Successful Requests/Second: 1.50
   📚 Literature Support: Villamizar et al. (2015), Dragoni et al. (2017)
   📝 Definition: Number of successful order requests processed per second
   🎯 Academic Significance: Primary performance indicator for microservices evaluation

2. RESPONSE TIME DISTRIBUTION  
   ✓ P50 (Median): 13 ms
   ✓ P95 (95th Percentile): 17 ms
   ✓ P99 (99th Percentile): 31 ms
   ✓ Average Response Time: 13.63 ms
   📚 Literature Support: Dean & Barroso (2013) "The tail at scale"
   📝 Definition: API request response time percentile distribution
   🎯 Academic Significance: Tail latency critical for large-scale system performance

3. ERROR RATE
   ✓ Failed Requests: 0
   ✓ Total Requests: 90
   ✓ Error Rate: 0.00%
   📚 Literature Support: Newman (2015), Fowler & Lewis (2014)
   📝 Definition: Percentage of failed requests relative to total requests
   🎯 Academic Significance: System reliability and robustness indicator

4. CACHE EFFECTIVENESS (Idempotency Mechanism)
   ✓ Repeated Requests: 27
   ✓ Successfully Handled Repeats: 27
   ✓ Cache Effectiveness: 100.00%
   📚 Literature Support: Nishtala et al. (2013) Facebook Memcache Study
   📝 Definition: Success rate of Redis idempotency cache in handling duplicate requests
   🎯 Academic Significance: Consistency mechanism efficiency measurement

=================================================
EXPERIMENTAL DATA FILES
=================================================
Detailed Results CSV: ../results/baseline/20250802_225456/detailed_results.csv
Response Time Data: ../results/baseline/20250802_225456/response_times.txt
Core Metrics Report: ../results/baseline/20250802_225456/core_metrics_report.txt
Initial System State: ../results/baseline/20250802_225456/initial_inventory.json
Final System State: ../results/baseline/20250802_225456/final_inventory.json

=================================================
ACADEMIC CITATION TEMPLATE
=================================================
"This study employs four literature-supported core metrics to evaluate 
microservices consistency mechanism performance. Throughput and response 
time distribution follow the methodological framework established by 
Dean & Barroso (2013) and Villamizar et al. (2015) for microservices 
performance assessment. Error rate measurement aligns with Newman (2015)'s 
reliability evaluation framework. Cache effectiveness evaluation adapts 
the large-scale caching system assessment approach from Nishtala et al. (2013)."

=================================================
EXPERIMENTAL VALIDATION STATUS
=================================================
✅ Data Collection: Complete
✅ Metrics Calculation: Complete  
✅ Literature Alignment: Verified
✅ Academic Standards: Compliant
🎓 Ready for thesis integration

=================================================
PERFORMANCE ANALYSIS SUMMARY
=================================================
System Performance: MEDIUM
Response Time Performance: EXCELLENT
System Reliability: HIGH
Idempotency Effectiveness: EXCELLENT
